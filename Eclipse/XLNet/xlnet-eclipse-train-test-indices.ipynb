{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-28T09:22:12.245296Z","iopub.execute_input":"2022-02-28T09:22:12.245851Z","iopub.status.idle":"2022-02-28T09:22:12.28613Z","shell.execute_reply.started":"2022-02-28T09:22:12.245756Z","shell.execute_reply":"2022-02-28T09:22:12.284995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom random import seed\nfrom random import randint\nimport random\nimport string\nimport re\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:12.288557Z","iopub.execute_input":"2022-02-28T09:22:12.290447Z","iopub.status.idle":"2022-02-28T09:22:12.296155Z","shell.execute_reply.started":"2022-02-28T09:22:12.290411Z","shell.execute_reply":"2022-02-28T09:22:12.294691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport transformers\n\nimport nltk\n\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\nplt.style.use('seaborn')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:12.297854Z","iopub.execute_input":"2022-02-28T09:22:12.299897Z","iopub.status.idle":"2022-02-28T09:22:16.054694Z","shell.execute_reply.started":"2022-02-28T09:22:12.299334Z","shell.execute_reply":"2022-02-28T09:22:16.053698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:16.057938Z","iopub.execute_input":"2022-02-28T09:22:16.058591Z","iopub.status.idle":"2022-02-28T09:22:16.277694Z","shell.execute_reply.started":"2022-02-28T09:22:16.058541Z","shell.execute_reply":"2022-02-28T09:22:16.276605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Input, Reshape, Conv1D, Conv2D, BatchNormalization, MaxPooling1D, MaxPooling2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, Sequential\n# from tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:16.279483Z","iopub.execute_input":"2022-02-28T09:22:16.279814Z","iopub.status.idle":"2022-02-28T09:22:22.451476Z","shell.execute_reply.started":"2022-02-28T09:22:16.279771Z","shell.execute_reply":"2022-02-28T09:22:22.450226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed(1)\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:22.453399Z","iopub.execute_input":"2022-02-28T09:22:22.453719Z","iopub.status.idle":"2022-02-28T09:22:22.465453Z","shell.execute_reply.started":"2022-02-28T09:22:22.453676Z","shell.execute_reply":"2022-02-28T09:22:22.464416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:22.469204Z","iopub.execute_input":"2022-02-28T09:22:22.470066Z","iopub.status.idle":"2022-02-28T09:22:22.541727Z","shell.execute_reply.started":"2022-02-28T09:22:22.470021Z","shell.execute_reply":"2022-02-28T09:22:22.540382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_CSV_TRAIN = '../input/eclipse-preprocessed45/eclipse_preprocessed_os.csv'\n\ndataset = pd.read_csv(PATH_CSV_TRAIN)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:22.546813Z","iopub.execute_input":"2022-02-28T09:22:22.547163Z","iopub.status.idle":"2022-02-28T09:22:30.999126Z","shell.execute_reply.started":"2022-02-28T09:22:22.547121Z","shell.execute_reply":"2022-02-28T09:22:30.998086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.dropna(subset = [\"description1\"], inplace=True)\ndataset.dropna(subset = [\"description2\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:31.000642Z","iopub.execute_input":"2022-02-28T09:22:31.001366Z","iopub.status.idle":"2022-02-28T09:22:31.20783Z","shell.execute_reply.started":"2022-02-28T09:22:31.00132Z","shell.execute_reply":"2022-02-28T09:22:31.206834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reset_column_names():\n  dataset.drop('description1', axis=1, inplace=True)\n  dataset.drop('short_desc1', axis=1, inplace=True)\n  dataset.drop('description2', axis=1, inplace=True)\n  dataset.drop('short_desc2', axis=1, inplace=True)\n\n  dataset.rename(columns={'description1_clean':'description1','short_desc1_clean':'short_desc1','description2_clean':'description2','short_desc2_clean':'short_desc2'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:31.210378Z","iopub.execute_input":"2022-02-28T09:22:31.210634Z","iopub.status.idle":"2022-02-28T09:22:31.218928Z","shell.execute_reply.started":"2022-02-28T09:22:31.210603Z","shell.execute_reply":"2022-02-28T09:22:31.217869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    clean=text\n    \n    reg = re.compile(r\" +\")\n    clean = clean.apply(lambda r: re.sub(reg, string=r, repl=' '))\n\n    #Lowercase\n    clean = clean.apply(lambda r: r.lower())\n    return clean","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:31.220647Z","iopub.execute_input":"2022-02-28T09:22:31.221206Z","iopub.status.idle":"2022-02-28T09:22:31.231615Z","shell.execute_reply.started":"2022-02-28T09:22:31.221157Z","shell.execute_reply":"2022-02-28T09:22:31.230515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['description1_clean'] = clean_text(dataset['description1'])\ndataset['short_desc1_clean'] = clean_text(dataset['short_desc1'])\ndataset['description2_clean'] = clean_text(dataset['description2'])\ndataset['short_desc2_clean'] = clean_text(dataset['short_desc2'])\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:31.233101Z","iopub.execute_input":"2022-02-28T09:22:31.233957Z","iopub.status.idle":"2022-02-28T09:22:51.691851Z","shell.execute_reply.started":"2022-02-28T09:22:31.233882Z","shell.execute_reply":"2022-02-28T09:22:51.690852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_column_names()","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:51.693722Z","iopub.execute_input":"2022-02-28T09:22:51.694247Z","iopub.status.idle":"2022-02-28T09:22:52.058142Z","shell.execute_reply.started":"2022-02-28T09:22:51.694199Z","shell.execute_reply":"2022-02-28T09:22:52.057139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:52.061211Z","iopub.execute_input":"2022-02-28T09:22:52.061759Z","iopub.status.idle":"2022-02-28T09:22:52.088208Z","shell.execute_reply.started":"2022-02-28T09:22:52.061713Z","shell.execute_reply":"2022-02-28T09:22:52.087031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in dataset.iterrows():\n    desc = row['description1'] + row['description2']\n    dataset.loc[index, 'description'] = desc","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:22:52.100749Z","iopub.execute_input":"2022-02-28T09:22:52.101426Z","iopub.status.idle":"2022-02-28T09:45:04.423886Z","shell.execute_reply.started":"2022-02-28T09:22:52.101379Z","shell.execute_reply":"2022-02-28T09:45:04.422827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dataset['description']\nY = np.array(dataset.duplicate.values, dtype='int')\n\nkfold = StratifiedKFold()\ni = 0\n    \nfor train, test in kfold.split(X, Y):\n    if(i == 0):\n        with open('train1.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in train]))\n        with open('test1.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in test]))\n    elif(i==1):\n        with open('train2.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in train]))\n        with open('test2.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in test]))\n    elif(i==2):\n        with open('train3.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in train]))\n        with open('test3.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in test]))\n    elif(i==3):\n        with open('train4.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in train]))\n        with open('test4.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in test]))\n    elif(i==4):\n        with open('train5.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in train]))\n        with open('test5.txt', 'w') as f:\n            f.write('\\n'.join([str(tr) for tr in test]))\n            \n    i = i+1","metadata":{"execution":{"iopub.status.busy":"2022-02-28T09:45:04.521387Z","iopub.execute_input":"2022-02-28T09:45:04.522692Z","iopub.status.idle":"2022-02-28T09:45:05.587733Z","shell.execute_reply.started":"2022-02-28T09:45:04.522642Z","shell.execute_reply":"2022-02-28T09:45:05.586715Z"},"trusted":true},"execution_count":null,"outputs":[]}]}