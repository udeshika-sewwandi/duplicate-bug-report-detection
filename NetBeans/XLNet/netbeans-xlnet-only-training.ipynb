{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-20T03:01:28.961222Z","iopub.execute_input":"2022-03-20T03:01:28.961590Z","iopub.status.idle":"2022-03-20T03:01:29.001955Z","shell.execute_reply.started":"2022-03-20T03:01:28.961511Z","shell.execute_reply":"2022-03-20T03:01:29.001230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom random import seed\nfrom random import randint\nimport random\nimport string\nimport re\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:29.003672Z","iopub.execute_input":"2022-03-20T03:01:29.003927Z","iopub.status.idle":"2022-03-20T03:01:29.008046Z","shell.execute_reply.started":"2022-03-20T03:01:29.003893Z","shell.execute_reply":"2022-03-20T03:01:29.007381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport transformers\n\nimport nltk\n\n\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n\nplt.style.use('seaborn')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:29.009212Z","iopub.execute_input":"2022-03-20T03:01:29.009770Z","iopub.status.idle":"2022-03-20T03:01:31.838517Z","shell.execute_reply.started":"2022-03-20T03:01:29.009727Z","shell.execute_reply":"2022-03-20T03:01:31.837777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nnltk.download(\"stopwords\")\nfrom nltk.corpus import stopwords","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:31.840899Z","iopub.execute_input":"2022-03-20T03:01:31.841163Z","iopub.status.idle":"2022-03-20T03:01:32.006733Z","shell.execute_reply.started":"2022-03-20T03:01:31.841129Z","shell.execute_reply":"2022-03-20T03:01:32.005227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Input, Reshape, Conv1D, Conv2D, BatchNormalization, MaxPooling1D, MaxPooling2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, Sequential\n# from tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow_hub as hub\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:32.008128Z","iopub.execute_input":"2022-03-20T03:01:32.008614Z","iopub.status.idle":"2022-03-20T03:01:36.976568Z","shell.execute_reply.started":"2022-03-20T03:01:32.008574Z","shell.execute_reply":"2022-03-20T03:01:36.975827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed(1)\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:36.979153Z","iopub.execute_input":"2022-03-20T03:01:36.979667Z","iopub.status.idle":"2022-03-20T03:01:36.985422Z","shell.execute_reply.started":"2022-03-20T03:01:36.979629Z","shell.execute_reply":"2022-03-20T03:01:36.984845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:36.987240Z","iopub.execute_input":"2022-03-20T03:01:36.987736Z","iopub.status.idle":"2022-03-20T03:01:37.048016Z","shell.execute_reply.started":"2022-03-20T03:01:36.987696Z","shell.execute_reply":"2022-03-20T03:01:37.047242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_indices = []\ntest_indices = []\n\nwith open('../input/netbeans-train-test5/nb_train5.txt') as f:\n    train_indices = f.readlines()\n\nwith open('../input/netbeans-train-test5/nb_test5.txt') as f:\n    test_indices = f.readlines()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.049191Z","iopub.execute_input":"2022-03-20T03:01:37.049983Z","iopub.status.idle":"2022-03-20T03:01:37.089567Z","shell.execute_reply.started":"2022-03-20T03:01:37.049943Z","shell.execute_reply":"2022-03-20T03:01:37.088918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_indices = [int(tr.split('\\n')[0]) for tr in train_indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.090803Z","iopub.execute_input":"2022-03-20T03:01:37.091408Z","iopub.status.idle":"2022-03-20T03:01:37.152326Z","shell.execute_reply.started":"2022-03-20T03:01:37.091362Z","shell.execute_reply":"2022-03-20T03:01:37.151777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_indices)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.155588Z","iopub.execute_input":"2022-03-20T03:01:37.156155Z","iopub.status.idle":"2022-03-20T03:01:37.163196Z","shell.execute_reply.started":"2022-03-20T03:01:37.156119Z","shell.execute_reply":"2022-03-20T03:01:37.162545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_indices  = [int(te.split('\\n')[0]) for te in test_indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.164209Z","iopub.execute_input":"2022-03-20T03:01:37.164827Z","iopub.status.idle":"2022-03-20T03:01:37.183776Z","shell.execute_reply.started":"2022-03-20T03:01:37.164779Z","shell.execute_reply":"2022-03-20T03:01:37.183103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_indices)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.184869Z","iopub.execute_input":"2022-03-20T03:01:37.185262Z","iopub.status.idle":"2022-03-20T03:01:37.193159Z","shell.execute_reply.started":"2022-03-20T03:01:37.185226Z","shell.execute_reply":"2022-03-20T03:01:37.192364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_CSV_TRAIN = '../input/netbeans/netbeans_preprocessed_os.csv'#dataset: netbeans_preprocessed5 need to rename\n# PATH_CSV_TEST = '../input/nlpgettingstarted/test.csv'\n# PATH_CSV_SUBMISSION = '../input/nlpgettingstarted/sample_submission.csv'\n\ndataset = pd.read_csv(PATH_CSV_TRAIN)\n# dataf_test = pd.read_csv(PATH_CSV_TEST)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:37.194308Z","iopub.execute_input":"2022-03-20T03:01:37.194641Z","iopub.status.idle":"2022-03-20T03:01:47.049005Z","shell.execute_reply.started":"2022-03-20T03:01:37.194605Z","shell.execute_reply":"2022-03-20T03:01:47.047153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.dropna(subset = [\"description1\"], inplace=True)\ndataset.dropna(subset = [\"description2\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:47.051567Z","iopub.execute_input":"2022-03-20T03:01:47.051844Z","iopub.status.idle":"2022-03-20T03:01:47.339863Z","shell.execute_reply.started":"2022-03-20T03:01:47.051807Z","shell.execute_reply":"2022-03-20T03:01:47.339112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in dataset.iterrows():\n    doc1 = 'Product:' + row['product'] + '.Component:' + row['component'] + '.Description:' + row['description1'] #+ '.Summary:' + row['short_desc1']\n#     print(row['bug_id'])\n#     print(row['description2'])\n    doc2 = 'Product:' + row['product'] + '.Component:' + row['component'] + '.Description:' + row['description2'] #+ '.Summary:' + row['short_desc2']\n    dataset.loc[index, 'doc1'] = doc1\n    dataset.loc[index, 'doc2'] = doc2","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:01:47.341295Z","iopub.execute_input":"2022-03-20T03:01:47.341589Z","iopub.status.idle":"2022-03-20T03:28:32.001957Z","shell.execute_reply.started":"2022-03-20T03:01:47.341550Z","shell.execute_reply":"2022-03-20T03:28:32.001109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for index, row in dataset.iterrows():\n    desc = row['doc1'] + row['doc2']\n    dataset.loc[index, 'description'] = desc","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:28:32.003541Z","iopub.execute_input":"2022-03-20T03:28:32.003791Z","iopub.status.idle":"2022-03-20T03:39:08.949596Z","shell.execute_reply.started":"2022-03-20T03:28:32.003756Z","shell.execute_reply":"2022-03-20T03:39:08.948845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reset_column_names():\n  dataset.drop('description', axis=1, inplace=True)\n#   dataset.drop('short_desc1', axis=1, inplace=True)\n#   dataset.drop('description2', axis=1, inplace=True)\n#   dataset.drop('short_desc2', axis=1, inplace=True)\n\n  dataset.rename(columns={'description_clean':'description'}, inplace=True) #,'short_desc1_clean':'short_desc1','description2_clean':'description2','short_desc2_clean':'short_desc2'","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:08.951143Z","iopub.execute_input":"2022-03-20T03:39:08.951706Z","iopub.status.idle":"2022-03-20T03:39:08.957397Z","shell.execute_reply.started":"2022-03-20T03:39:08.951661Z","shell.execute_reply":"2022-03-20T03:39:08.956526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    clean=text\n    \n    reg = re.compile(r\" +\")\n    clean = clean.apply(lambda r: re.sub(reg, string=r, repl=' '))\n\n    #Lowercase\n    clean = clean.apply(lambda r: r.lower())\n    return clean","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:08.958815Z","iopub.execute_input":"2022-03-20T03:39:08.959378Z","iopub.status.idle":"2022-03-20T03:39:08.967659Z","shell.execute_reply.started":"2022-03-20T03:39:08.959292Z","shell.execute_reply":"2022-03-20T03:39:08.967042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['description_clean'] = clean_text(dataset['description'])\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:08.969580Z","iopub.execute_input":"2022-03-20T03:39:08.970186Z","iopub.status.idle":"2022-03-20T03:39:26.190031Z","shell.execute_reply.started":"2022-03-20T03:39:08.970149Z","shell.execute_reply":"2022-03-20T03:39:26.189329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reset_column_names()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:26.191288Z","iopub.execute_input":"2022-03-20T03:39:26.192669Z","iopub.status.idle":"2022-03-20T03:39:26.323827Z","shell.execute_reply.started":"2022-03-20T03:39:26.192626Z","shell.execute_reply":"2022-03-20T03:39:26.322986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:26.325236Z","iopub.execute_input":"2022-03-20T03:39:26.325530Z","iopub.status.idle":"2022-03-20T03:39:26.362584Z","shell.execute_reply.started":"2022-03-20T03:39:26.325478Z","shell.execute_reply":"2022-03-20T03:39:26.361929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for index, row in dataset.iterrows():\n#     desc = row['description1'] + row['description2']\n#     dataset.loc[index, 'description'] = desc","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:26.363753Z","iopub.execute_input":"2022-03-20T03:39:26.364104Z","iopub.status.idle":"2022-03-20T03:39:26.367881Z","shell.execute_reply.started":"2022-03-20T03:39:26.364061Z","shell.execute_reply":"2022-03-20T03:39:26.367066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFXLNetModel, XLNetTokenizer, XLNetConfig","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:26.369463Z","iopub.execute_input":"2022-03-20T03:39:26.369800Z","iopub.status.idle":"2022-03-20T03:39:26.650097Z","shell.execute_reply.started":"2022-03-20T03:39:26.369719Z","shell.execute_reply":"2022-03-20T03:39:26.649472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet_model = 'xlnet-base-cased'\nxlnet_tokenizer = XLNetTokenizer.from_pretrained(xlnet_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:26.652072Z","iopub.execute_input":"2022-03-20T03:39:26.652548Z","iopub.status.idle":"2022-03-20T03:39:28.064430Z","shell.execute_reply.started":"2022-03-20T03:39:26.652509Z","shell.execute_reply":"2022-03-20T03:39:28.063706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_xlnet(mname):\n    \"\"\" Creates the model. It is composed of the XLNet main block and then\n    a classification head its added\n    \"\"\"\n    # Define token ids as inputs\n    word_inputs = tf.keras.Input(shape=(160,), name='word_inputs', dtype='int32')\n\n    # Call XLNet model\n    xlnet = TFXLNetModel.from_pretrained(mname)\n    xlnet_encodings = xlnet(word_inputs)[0]\n\n    # CLASSIFICATION HEAD \n    # Collect last step from last hidden state (CLS)\n    doc_encoding = tf.squeeze(xlnet_encodings[:, -1:, :], axis=1)\n    # Apply dropout for regularization\n    doc_encoding = tf.keras.layers.Dropout(.1)(doc_encoding)\n    # Final output \n    outputs = tf.keras.layers.Dense(1, activation='sigmoid', name='outputs')(doc_encoding)\n\n    # Compile model\n    model = tf.keras.Model(inputs=[word_inputs], outputs=[outputs])\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.065839Z","iopub.execute_input":"2022-03-20T03:39:28.066095Z","iopub.status.idle":"2022-03-20T03:39:28.074296Z","shell.execute_reply.started":"2022-03-20T03:39:28.066058Z","shell.execute_reply":"2022-03-20T03:39:28.073546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_inputs(tweets, tokenizer, max_len=160):\n    \"\"\" Gets tensors from text using the tokenizer provided\"\"\"\n    inps = [tokenizer.encode_plus(t, max_length=max_len, pad_to_max_length=True, add_special_tokens=True) for t in tweets]\n    inp_tok = np.array([a['input_ids'] for a in inps])\n    ids = np.array([a['attention_mask'] for a in inps])\n    segments = np.array([a['token_type_ids'] for a in inps])\n    return inp_tok, ids, segments","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.075625Z","iopub.execute_input":"2022-03-20T03:39:28.076041Z","iopub.status.idle":"2022-03-20T03:39:28.083776Z","shell.execute_reply.started":"2022-03-20T03:39:28.076006Z","shell.execute_reply":"2022-03-20T03:39:28.083038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = dataset['description']\nY = np.array(dataset.duplicate.values, dtype='int')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.085307Z","iopub.execute_input":"2022-03-20T03:39:28.085846Z","iopub.status.idle":"2022-03-20T03:39:28.096504Z","shell.execute_reply.started":"2022-03-20T03:39:28.085808Z","shell.execute_reply":"2022-03-20T03:39:28.095840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X.iloc[train_indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.100556Z","iopub.execute_input":"2022-03-20T03:39:28.100893Z","iopub.status.idle":"2022-03-20T03:39:28.104290Z","shell.execute_reply.started":"2022-03-20T03:39:28.100859Z","shell.execute_reply":"2022-03-20T03:39:28.103516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Y[train_indices]","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.105603Z","iopub.execute_input":"2022-03-20T03:39:28.106295Z","iopub.status.idle":"2022-03-20T03:39:28.112278Z","shell.execute_reply.started":"2022-03-20T03:39:28.106258Z","shell.execute_reply":"2022-03-20T03:39:28.111559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_tok, ids, segments = get_inputs(X.iloc[train_indices], xlnet_tokenizer)\ny_train = np.array(Y[train_indices], dtype='int')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:39:28.113460Z","iopub.execute_input":"2022-03-20T03:39:28.114294Z","iopub.status.idle":"2022-03-20T03:57:18.661300Z","shell.execute_reply.started":"2022-03-20T03:39:28.114251Z","shell.execute_reply":"2022-03-20T03:57:18.660538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xlnet = create_xlnet(xlnet_model)\nxlnet.summary()\n# Fit the model  \nhist = xlnet.fit(x=inp_tok, y=y_train, epochs=7, batch_size=40)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T03:57:18.662704Z","iopub.execute_input":"2022-03-20T03:57:18.662953Z","iopub.status.idle":"2022-03-20T10:55:20.166404Z","shell.execute_reply.started":"2022-03-20T03:57:18.662920Z","shell.execute_reply":"2022-03-20T10:55:20.165511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xlnet.save(\"eclipse_xlnet\")","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:55:20.167994Z","iopub.execute_input":"2022-03-20T10:55:20.168241Z","iopub.status.idle":"2022-03-20T10:55:20.173699Z","shell.execute_reply.started":"2022-03-20T10:55:20.168206Z","shell.execute_reply":"2022-03-20T10:55:20.173049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_inp_tok, test_ids, test_segments = get_inputs(X.iloc[test_indices], xlnet_tokenizer)\ny_test = np.array(Y[test_indices], dtype='int')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T10:55:20.175325Z","iopub.execute_input":"2022-03-20T10:55:20.175826Z","iopub.status.idle":"2022-03-20T11:00:08.808211Z","shell.execute_reply.started":"2022-03-20T10:55:20.175785Z","shell.execute_reply":"2022-03-20T11:00:08.807473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\nscores = xlnet.evaluate(test_inp_tok,y_test, verbose=0)\nf1score = (2 * scores[2]*100 * scores[3]*100)/(scores[2]*100 + scores[3]*100)\nprint(\"%s: %.2f%%\" % (xlnet.metrics_names[1], scores[1]*100))\nprint(\"%s: %.2f%%\" % (xlnet.metrics_names[2], scores[2]*100))\nprint(\"%s: %.2f%%\" % (xlnet.metrics_names[3], scores[3]*100))\nprint(\"f1 score: \", (f1score))","metadata":{"execution":{"iopub.status.busy":"2022-03-20T11:00:08.809510Z","iopub.execute_input":"2022-03-20T11:00:08.809777Z","iopub.status.idle":"2022-03-20T11:05:06.689806Z","shell.execute_reply.started":"2022-03-20T11:00:08.809741Z","shell.execute_reply":"2022-03-20T11:05:06.689015Z"},"trusted":true},"execution_count":null,"outputs":[]}]}